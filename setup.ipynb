{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup cơ bản\n",
    "## Các thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import PyPDF2\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import chainlit as cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Các đường dẫn thư mục chứa thông tin ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(__file__).parent / \".files\"\n",
    "CHATS_DIR = BASE_DIR / \"chats\"\n",
    "PDF_DIR = BASE_DIR / \"pdf\"\n",
    "CHUNKS_DIR = BASE_DIR / \"chunks\"\n",
    "METADATA_FILE = BASE_DIR / \"metadata.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Đảm bảo các thư mục có tồn tại**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHATS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PDF_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CHUNKS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Khởi tạo metadata để lưu trữ các thông tin được tạo ra**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not METADATA_FILE.exists():\n",
    "    METADATA_FILE.write_text(json.dumps({\"files\": {}, \"chats\": {}}, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_local = ChatOllama(model=\"llama3.2:1b\", base_url=\"http://127.0.0.1:11434\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ở đây sử dụng ChatOllama\n",
    "- model: tên model\n",
    "- base url: lấy từ server của Ollama (Chạy `ollama serve` trong terminal để lấy url link) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tải và lưu metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "def load_metadata():\n",
    "    \"\"\"Load metadata from file.\"\"\"\n",
    "    with METADATA_FILE.open(\"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# save metadata\n",
    "def save_metadata(metadata):\n",
    "    \"\"\"Save metadata to file.\"\"\"\n",
    "    with METADATA_FILE.open(\"w\") as f:\n",
    "        json.dump(metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tạo các thư mục chat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chat folder\n",
    "def ensure_chat_folder(metadata):\n",
    "    \"\"\"Ensure the `chats` directory exists and create a new chat folder.\"\"\"\n",
    "    chat_index = len(metadata[\"chats\"]) + 1\n",
    "    chat_folder_name = f\"chat_{chat_index}\"\n",
    "    chat_folder = CHATS_DIR / chat_folder_name\n",
    "    chat_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Add chat entry to metadata\n",
    "    metadata[\"chats\"][chat_index] = {\"folder\": str(chat_folder), \"questions\": []}\n",
    "    save_metadata(metadata)\n",
    "\n",
    "    return chat_index, chat_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tách chữ khỏi pdf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    \"\"\"Extract text from PDF.\"\"\"\n",
    "    pdf = PyPDF2.PdfReader(file_path)\n",
    "    return \"\".join(page.extract_text() for page in pdf.pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tạo các folder chứa các chunk dữ liệu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks(filename, text):\n",
    "    \"\"\"Split text into chunks and save them.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    texts = text_splitter.split_text(text)\n",
    "\n",
    "    chunk_files = []\n",
    "    for idx, chunk in enumerate(texts):\n",
    "        chunk_file = CHUNKS_DIR / f\"chunk_{filename}_{idx}.txt\"\n",
    "        chunk_file.write_text(chunk)\n",
    "        chunk_files.append(str(chunk_file))\n",
    "    return chunk_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuỗi set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_chain():\n",
    "    \"\"\"Set up the retrieval chain using all available chunks.\"\"\"\n",
    "    chunk_files = list(CHUNKS_DIR.glob(\"chunk_*.txt\"))\n",
    "    chunk_texts = [chunk.read_text() for chunk in chunk_files]\n",
    "    metadatas = [{\"source\": str(chunk)} for chunk in chunk_files]\n",
    "\n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    docsearch = Chroma.from_texts(chunk_texts, embeddings, metadatas=metadatas)\n",
    "\n",
    "    # Set the retriever to return up to 4 documents\n",
    "    retriever = docsearch.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        output_key=\"answer\",\n",
    "        return_messages=True,\n",
    "    )\n",
    "\n",
    "    return ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm_local,\n",
    "        retriever=retriever,\n",
    "        memory=memory,\n",
    "        return_source_documents=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bắt đầu chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    language = \"vi-VN\"\n",
    "\n",
    "    root_path  = Path(__file__).parent\n",
    "    \n",
    "    translated_chainlit_md_path = root_path / f\"chainlit_{language}.md\"\n",
    "    default_chainlit_md_path = root_path / \"chainlit.md\"\n",
    "    if translated_chainlit_md_path.exists():\n",
    "        message = translated_chainlit_md_path.read_text()\n",
    "    else:\n",
    "        message = default_chainlit_md_path.read_text()\n",
    "    startup_message = cl.Message(content=message)\n",
    "    await startup_message.send()\n",
    "    \n",
    "    \"\"\"Handle the start of a new chat session.\"\"\"\n",
    "    metadata = load_metadata()\n",
    "\n",
    "    # Ensure chat folder structure and create a new chat folder\n",
    "    chat_index = len(metadata[\"chats\"]) + 1\n",
    "    chat_folder_name = f\"chat_{chat_index}\"\n",
    "    chat_folder = CHATS_DIR / chat_folder_name\n",
    "\n",
    "    if not chat_folder.exists():  # Ensure no duplicate folders\n",
    "        chat_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Add chat entry to metadata if it doesn't exist\n",
    "    if chat_index not in metadata[\"chats\"]:\n",
    "        metadata[\"chats\"][chat_index] = {\"folder\": str(chat_folder), \"questions\": []}\n",
    "        save_metadata(metadata)\n",
    "\n",
    "    # Store in user session\n",
    "    cl.user_session.set(\"chat_index\", chat_index)\n",
    "    cl.user_session.set(\"metadata\", metadata)\n",
    "\n",
    "    await cl.Message(content=f\"New chat started! Chat folder: `{chat_folder.name}`.\").send()\n",
    "\n",
    "    # If no files are present, ask the user to upload a PDF\n",
    "    if not metadata[\"files\"]:\n",
    "        await cl.Message(content=\"No files found. Please upload a PDF to start.\").send()\n",
    "        await prompt_for_file(chat_index)\n",
    "    else:\n",
    "        # Set up the chain with all available chunks\n",
    "        cl.user_session.set(\"chain\", setup_chain())\n",
    "        await cl.Message(content=\"You can start asking questions based on uploaded files.\").send()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`translated_chainlit_md_path = root_path / f\"chainlit_{language}.md\"` \\\n",
    "`default_chainlit_md_path = root_path / \"chainlit.md\"` \\\n",
    "Nối các file markdown để đưa lên chat bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload file lên bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def prompt_for_file(chat_index):\n",
    "    \"\"\"Prompt the user to upload a file and process it.\"\"\"\n",
    "    files = None\n",
    "    while files is None:\n",
    "        files = await cl.AskFileMessage(\n",
    "            content=\"Upload a PDF file:\",\n",
    "            accept={\"application/pdf\": [\".pdf\"]},\n",
    "            max_size_mb=100,\n",
    "            timeout=180,\n",
    "        ).send()\n",
    "\n",
    "    file = files[0]\n",
    "    uploaded_file_path = PDF_DIR / file.name\n",
    "\n",
    "    if uploaded_file_path.exists():\n",
    "        await cl.Message(content=f\"File `{file.name}` already exists. No need to re-upload.\").send()\n",
    "        return\n",
    "\n",
    "    os.rename(file.path, uploaded_file_path)\n",
    "\n",
    "    # Process the uploaded file\n",
    "    pdf_text = extract_text_from_pdf(uploaded_file_path)\n",
    "    create_chunks(file.name, pdf_text)\n",
    "\n",
    "    metadata = cl.user_session.get(\"metadata\")\n",
    "    metadata[\"files\"][file.name] = {\"file_name\": file.name}\n",
    "    save_metadata(metadata)\n",
    "\n",
    "    # Update chain with new chunks\n",
    "    cl.user_session.set(\"chain\", setup_chain())\n",
    "\n",
    "    await cl.Message(content=f\"File `{file.name}` processed successfully. You can now ask questions!\").send()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lý chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cl.on_message\n",
    "async def main(message: cl.Message):\n",
    "    metadata = cl.user_session.get(\"metadata\")\n",
    "    chat_index = cl.user_session.get(\"chat_index\")\n",
    "\n",
    "    # Validate chat index\n",
    "    if not chat_index or chat_index not in metadata[\"chats\"]:\n",
    "        await cl.Message(content=\"Error: Chat session not properly initialized.\").send()\n",
    "        return\n",
    "\n",
    "    chain = cl.user_session.get(\"chain\")\n",
    "    if not chain:\n",
    "        await cl.Message(content=\"No chain found. Please upload a file to continue.\").send()\n",
    "        return\n",
    "\n",
    "    # Check for file upload triggers\n",
    "    if message.content.lower() in [\"add a file\", \"thêm file\"]:\n",
    "        await prompt_for_file(chat_index)\n",
    "        return\n",
    "\n",
    "    # Process user query\n",
    "    cb = cl.AsyncLangchainCallbackHandler()\n",
    "    res = await chain.ainvoke(message.content, callbacks=[cb])\n",
    "\n",
    "    answer = res[\"answer\"]\n",
    "    source_documents = res[\"source_documents\"]\n",
    "\n",
    "    # Save the answer to a file\n",
    "    chat_folder = Path(metadata[\"chats\"][chat_index][\"folder\"])\n",
    "    answer_file = chat_folder / f\"answer_{len(metadata['chats'][chat_index]['questions']) + 1}.txt\"\n",
    "    answer_file.write_text(answer)\n",
    "\n",
    "    metadata[\"chats\"][chat_index][\"questions\"].append({\n",
    "        \"question\": message.content,\n",
    "        \"answer_file\": str(answer_file),\n",
    "    })\n",
    "    save_metadata(metadata)\n",
    "\n",
    "    # Send the answer to the user\n",
    "    sources_text = \"\\n\".join(f\"- {Path(doc.metadata['source']).name}\" for doc in source_documents)\n",
    "    await cl.Message(content=f\"{answer}\\n\\nSources:\\n{sources_text}\").send()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kết thúc chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cl.on_chat_end\n",
    "async def on_chat_end():\n",
    "    \"\"\"Handle the end of a chat session.\"\"\"\n",
    "    print(\"The user disconnected!\")\n",
    "    await cl.Message(content=\"Chat ended. You can start a new chat by typing a message or reloading the page.\").send()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Khởi động bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "chainlit run {path/app.py} -w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tham khảo\n",
    "[Github repo](https://github.com/sudarshan-koirala/rag-chat-with-pdf) \\\n",
    "[Advanced model with summarize and picture](https://medium.com/@joshjtw/building-an-advanced-langchain-rag-chatbot-with-image-retrieval-and-agentic-routing-519f7765aa82) \\\n",
    "[Fine tuning llama](https://www.datacamp.com/tutorial/llama3-fine-tuning-locally)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
