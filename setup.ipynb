{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup cơ bản\n",
    "## Các thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import PyPDF2\n",
    "from PIL import Image  # For image processing\n",
    "import pytesseract  # For OCR (Optical Character Recognition)\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import chainlit as cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Các đường dẫn thư mục chứa thông tin ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(__file__).parent / \".files\" # Thư mục gốc\n",
    "CHATS_DIR = BASE_DIR / \"chats\" # \n",
    "PDF_DIR = BASE_DIR / \"pdf\"\n",
    "CHUNKS_DIR = BASE_DIR / \"chunks\"\n",
    "IMAGES_DIR = BASE_DIR / \"images\"\n",
    "METADATA_FILE = BASE_DIR / \"metadata.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Đảm bảo các thư mục có tồn tại**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHATS_DIR.mkdir(parents=True, exist_ok=True) \n",
    "PDF_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CHUNKS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "IMAGES_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Khởi tạo metadata để lưu trữ các thông tin được tạo ra**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not METADATA_FILE.exists():\n",
    "    METADATA_FILE.write_text(json.dumps({\"files\": {}, \"chats\": {}, \"images\": {}}, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_local = ChatOllama(model=\"llama3.2:1b\", base_url=\"http://127.0.0.1:11434\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ở đây sử dụng ChatOllama\n",
    "- `model`: tên model\n",
    "- `base_url`: lấy từ server của Ollama (Chạy `ollama serve` trong terminal để lấy url link) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tải và lưu metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "def load_metadata():\n",
    "    \"\"\"Load metadata from file.\"\"\"\n",
    "    with METADATA_FILE.open(\"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# save metadata\n",
    "def save_metadata(metadata):\n",
    "    \"\"\"Save metadata to file.\"\"\"\n",
    "    with METADATA_FILE.open(\"w\") as f:\n",
    "        json.dump(metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tạo các thư mục chat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chat folder\n",
    "def ensure_chat_folder(metadata):\n",
    "    \"\"\"Ensure the `chats` directory exists and create a new chat folder.\"\"\"\n",
    "    chat_index = len(metadata[\"chats\"]) + 1\n",
    "    chat_folder_name = f\"chat_{chat_index}\"\n",
    "    chat_folder = CHATS_DIR / chat_folder_name\n",
    "    chat_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Add chat entry to metadata\n",
    "    metadata[\"chats\"][chat_index] = {\"folder\": str(chat_folder), \"questions\": []}\n",
    "    save_metadata(metadata)\n",
    "\n",
    "    return chat_index, chat_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tách chữ từ hình ảnh và pdf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    \"\"\"Extract text from PDF.\"\"\"\n",
    "    pdf = PyPDF2.PdfReader(file_path)\n",
    "    return \"\".join(page.extract_text() for page in pdf.pages)\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    \"\"\"Extract text from an image using OCR.\"\"\"\n",
    "    return pytesseract.image_to_string(Image.open(image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tạo các folder chứa các chunk dữ liệu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks(filename, text):\n",
    "    \"\"\"Split text into chunks and save them.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    texts = text_splitter.split_text(text)\n",
    "\n",
    "    chunk_files = []\n",
    "    for idx, chunk in enumerate(texts):\n",
    "        chunk_file_name = f\"chunk_{Path(filename).stem}_{idx}.txt\"\n",
    "        chunk_file = CHUNKS_DIR / chunk_file_name\n",
    "        chunk_file.write_text(chunk)\n",
    "        chunk_files.append(str(chunk_file))\n",
    "    return chunk_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuỗi set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_chain():\n",
    "    \"\"\"Set up the retrieval chain using all available chunks.\"\"\"\n",
    "    chunk_files = list(CHUNKS_DIR.glob(\"chunk_*.txt\"))\n",
    "    chunk_texts = [chunk.read_text() for chunk in chunk_files]\n",
    "    metadatas = [{\"source\": str(chunk)} for chunk in chunk_files]\n",
    "\n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    docsearch = Chroma.from_texts(chunk_texts, embeddings, metadatas=metadatas)\n",
    "\n",
    "    # Set the retriever to return up to 4 documents\n",
    "    retriever = docsearch.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        output_key=\"answer\",\n",
    "        return_messages=True,\n",
    "    )\n",
    "\n",
    "    return ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm_local,\n",
    "        retriever=retriever,\n",
    "        memory=memory,\n",
    "        return_source_documents=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`retriever = docsearch.as_retriever(search_kwargs={\"k\": 4})` Có thể chỉnh k số lượng chunk được tìm kiếm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bắt đầu chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    language = \"vi-VN\"\n",
    "\n",
    "    root_path  = Path(__file__).parent\n",
    "    \n",
    "    translated_chainlit_md_path = root_path / f\"chainlit_{language}.md\"\n",
    "    default_chainlit_md_path = root_path / \"chainlit.md\"\n",
    "    if translated_chainlit_md_path.exists():\n",
    "        message = translated_chainlit_md_path.read_text()\n",
    "    else:\n",
    "        message = default_chainlit_md_path.read_text()\n",
    "    startup_message = cl.Message(content=message)\n",
    "    await startup_message.send()\n",
    "    \n",
    "    \"\"\"Handle the start of a new chat session.\"\"\"\n",
    "    metadata = load_metadata()\n",
    "\n",
    "    # Ensure chat folder structure and create a new chat folder\n",
    "    chat_index, chat_folder = ensure_chat_folder(metadata)\n",
    "\n",
    "    # Store chat info in user session\n",
    "    cl.user_session.set(\"chat_index\", chat_index)\n",
    "    cl.user_session.set(\"metadata\", metadata)\n",
    "\n",
    "    await cl.Message(content=f\"New chat started! Chat folder: `{chat_folder.name}`.\").send()\n",
    "\n",
    "    # Prompt for file if no files are available\n",
    "    if not metadata[\"files\"]:\n",
    "        await cl.Message(content=\"No files found. Please upload a PDF to start.\").send()\n",
    "        await prompt_for_file(chat_index)\n",
    "    else:\n",
    "        # Set up the chain with all available chunks\n",
    "        cl.user_session.set(\"chain\", setup_chain())\n",
    "        await cl.Message(content=\"You can start asking questions based on uploaded files.\").send()\n",
    "        \n",
    "async def prompt_for_file(chat_index):\n",
    "    \"\"\"Prompt the user to upload a file (PDF or image) and process it.\"\"\"\n",
    "    files = None\n",
    "    while files is None:\n",
    "        files = await cl.AskFileMessage(\n",
    "            content=\"Upload a file (PDF or image):\",\n",
    "            accept={\n",
    "                \"application/pdf\": [\".pdf\"],\n",
    "                \"image/jpeg\": [\".jpg\", \".jpeg\"],\n",
    "                \"image/png\": [\".png\"],\n",
    "            },\n",
    "            max_size_mb=100,\n",
    "            timeout=180,\n",
    "        ).send()\n",
    "\n",
    "    metadata = cl.user_session.get(\"metadata\")\n",
    "\n",
    "    for file in files:\n",
    "        file_extension = Path(file.name).suffix.lower()\n",
    "\n",
    "        if file_extension == \".pdf\":\n",
    "            uploaded_file_path = PDF_DIR / file.name\n",
    "            if not uploaded_file_path.exists():\n",
    "                os.rename(file.path, uploaded_file_path)\n",
    "                pdf_text = extract_text_from_pdf(uploaded_file_path)\n",
    "                create_chunks(file.name, pdf_text)\n",
    "\n",
    "                metadata[\"files\"][file.name] = {\"file_name\": file.name}\n",
    "                save_metadata(metadata)\n",
    "\n",
    "        elif file_extension in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "            uploaded_image_path = IMAGES_DIR / file.name\n",
    "            if not uploaded_image_path.exists():\n",
    "                os.rename(file.path, uploaded_image_path)\n",
    "                extracted_text = extract_text_from_image(uploaded_image_path)\n",
    "                create_chunks(file.name, extracted_text)\n",
    "\n",
    "                metadata[\"images\"][file.name] = {\"file_name\": file.name}\n",
    "                save_metadata(metadata)\n",
    "\n",
    "    await cl.Message(content=\"Files uploaded and processed successfully.\").send() \n",
    "    cl.user_session.set(\"chain\", setup_chain())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khi bắt đầu một đoạn chat, hệ thống sẽ kiểm tra xem nếu có bất kì file nào đã được upload lên chưa (trong `metadata`). Nếu không có sẽ yêu cầu upload file lên. Mỗi đoạn chat sẽ có folder riêng được tạo và lưu lại trong metadata. \\\n",
    "`prompt_for_file`: xử lý các file được tải lên, có thể là pdf, jpeg, png,... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lý chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cl.on_message\n",
    "async def main(message: cl.Message):\n",
    "    metadata = cl.user_session.get(\"metadata\")\n",
    "    chat_index = cl.user_session.get(\"chat_index\")\n",
    "\n",
    "    # Validate chat index\n",
    "    if not chat_index or chat_index not in metadata[\"chats\"]:\n",
    "        await cl.Message(content=\"Error: Chat session not properly initialized.\").send()\n",
    "        return\n",
    "\n",
    "    chain = cl.user_session.get(\"chain\")\n",
    "    if not chain:\n",
    "        await cl.Message(content=\"No chain found. Please upload a file to continue.\").send()\n",
    "        return\n",
    "\n",
    "    # Handle attached files (PDFs and Images)\n",
    "    if message.elements:\n",
    "        for file in message.elements:\n",
    "            file_extension = Path(file.name).suffix.lower()\n",
    "\n",
    "            # Handle PDFs\n",
    "            if file_extension == \".pdf\":\n",
    "                uploaded_file_path = PDF_DIR / file.name\n",
    "                os.rename(file.path, uploaded_file_path)\n",
    "\n",
    "                pdf_text = extract_text_from_pdf(uploaded_file_path)\n",
    "                create_chunks(file.name, pdf_text)\n",
    "\n",
    "                metadata[\"files\"][file.name] = {\"file_name\": file.name}\n",
    "                save_metadata(metadata)\n",
    "                await cl.Message(content=f\"PDF `{file.name}` processed successfully.\").send()\n",
    "\n",
    "            # Handle Images\n",
    "            elif file_extension in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "                uploaded_image_path = IMAGES_DIR / file.name\n",
    "                os.rename(file.path, uploaded_image_path)\n",
    "\n",
    "                extracted_text = extract_text_from_image(uploaded_image_path)\n",
    "                if extracted_text.strip():\n",
    "                    create_chunks(file.name, extracted_text)\n",
    "                    metadata[\"images\"][file.name] = {\"file_name\": file.name}\n",
    "                    save_metadata(metadata)\n",
    "                    await cl.Message(content=f\"Text extracted from image `{file.name}`:\\n\\n{extracted_text}\").send()\n",
    "                else:\n",
    "                    await cl.Message(content=f\"No text found in image `{file.name}`.\").send()\n",
    "\n",
    "        cl.user_session.set(\"chain\", setup_chain())\n",
    "        return\n",
    "\n",
    "    # Process user queries if no files are attached\n",
    "    cb = cl.AsyncLangchainCallbackHandler()\n",
    "    res = await chain.ainvoke(message.content, callbacks=[cb])\n",
    "\n",
    "    answer = res[\"answer\"]\n",
    "    source_documents = res[\"source_documents\"]\n",
    "\n",
    "    # Save the answer to a file\n",
    "    chat_folder = Path(metadata[\"chats\"][chat_index][\"folder\"])\n",
    "    answer_file = chat_folder / f\"answer_{len(metadata['chats'][chat_index]['questions']) + 1}.txt\"\n",
    "    answer_file.write_text(answer)\n",
    "\n",
    "    metadata[\"chats\"][chat_index][\"questions\"].append({\n",
    "        \"question\": message.content,\n",
    "        \"answer_file\": str(answer_file),\n",
    "    })\n",
    "    save_metadata(metadata)\n",
    "\n",
    "    # Send the answer to the user\n",
    "    sources_text = \"\\n\".join(f\"- {Path(doc.metadata['source']).name}\" for doc in source_documents)\n",
    "    await cl.Message(content=f\"{answer}\\n\\nSources:\\n{sources_text}\").send()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có thể xử lý các tệp đính kèm trong query của người dùng. Tuy nhiên, không thể trả lời câu hỏi đi kèm, chỉ có thể trả lời sau khi file được tải lên hoàn toàn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kết thúc chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cl.on_chat_end\n",
    "async def on_chat_end():\n",
    "    \"\"\"Handle the end of a chat session.\"\"\"\n",
    "    print(\"The user disconnected!\")\n",
    "    await cl.Message(content=\"Chat ended. You can start a new chat by typing a message or reloading the page.\").send()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Khởi động bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "chainlit run {path/app.py} -w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-w` để xem những thay đổi cũng như nếu có sự thay đổi nào trong đoạn code, chat sẽ tự động reload lại"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tham khảo\n",
    "[Github repo](https://github.com/sudarshan-koirala/rag-chat-with-pdf) \\\n",
    "[Advanced model with summarize and picture](https://medium.com/@joshjtw/building-an-advanced-langchain-rag-chatbot-with-image-retrieval-and-agentic-routing-519f7765aa82) \\\n",
    "[Fine tuning llama](https://www.datacamp.com/tutorial/llama3-fine-tuning-locally) \\\n",
    "[Language setup](https://docs.chainlit.io/customisation/translation) \\\n",
    "[Advanced document langchain](https://github.com/gkamradt/langchain-tutorials/blob/main/data_generation/Advanced%20Retrieval%20With%20LangChain.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
